{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def split_dataset (dataset ,split_ratio): # numpy\n",
    "    training_set = []\n",
    "    training_size = int(len(dataset)*split_ratio)\n",
    "    temp_test_dataset = list(dataset)\n",
    "    random_row_number = 0\n",
    "    random_row = []\n",
    "    while (len(training_set)<training_size):\n",
    "        random_row_number = random.randrange(len(temp_test_dataset))\n",
    "        random_row = temp_test_dataset.pop(random_row_number)\n",
    "        training_set.append(random_row)\n",
    "    test_dataset = temp_test_dataset\n",
    "    return [training_set, test_dataset]\n",
    "\n",
    "\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "\n",
    "def categorize_into_classes (dataset):\n",
    "    list_of_classes = []\n",
    "    list_of_classes = np.unique(dataset[:,-1])\n",
    "    classes_features_dict = {}\n",
    "    \n",
    "    for i in list_of_classes:\n",
    "        data_for_the_class =  dataset[dataset[:,-1]==i].copy()\n",
    "        data_for_the_class = data_for_the_class[:,:-1].copy() # cutting off the last column\n",
    "        classes_features_dict[i] = data_for_the_class\n",
    "    return classes_features_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_stats(dataset):\n",
    "    temp_mean = 0\n",
    "    std_dev = 0\n",
    "    stats_array = []\n",
    "    # dataset = dataset[:,:-1].copy() # removed the last column\n",
    "    index = 0\n",
    "    for index in range(np.size(dataset,1)):\n",
    "        temp_mean = mean(dataset[:,index])\n",
    "        std_dev = stdev(dataset[:,index])\n",
    "        if (std_dev==0):\n",
    "            std_dev = 0.0000022\n",
    "        stats_array.append([temp_mean,std_dev])\n",
    "        \n",
    "    return stats_array\n",
    "\n",
    "def generate_stats_by_class(dataset):\n",
    "\n",
    "    no_of_features = dataset[1].shape[0]\n",
    "    classes_features_dict = categorize_into_classes (dataset)\n",
    "    class_wise_stats = {}\n",
    "    for class_value, class_data in classes_features_dict.items():\n",
    "        class_wise_stats[class_value] = generate_stats(class_data)\n",
    "\n",
    "    cov_matrix = np.cov(dataset[:,:-1],rowvar=False)+0.2*np.identity(no_of_features-1)\n",
    "    return (class_wise_stats,cov_matrix)\n",
    "\n",
    "def calculate_probability(x, mean_vector, cov_matrix):\n",
    "    \n",
    "   \n",
    "    cov_matrix_inv = np.linalg.inv(cov_matrix)\n",
    "    cov_matrix_det = np.linalg.det(cov_matrix)\n",
    "    \n",
    "    no_of_features = x.shape[0]\n",
    "    \n",
    "    factor = 1/(math.sqrt(math.pow((2 * math.pi),no_of_features)*cov_matrix_det))\n",
    "    firstfactor = (x-mean_vector).T\n",
    "    secondfactor = (x-mean_vector)\n",
    "    \n",
    "    temp = (1/2) *firstfactor@cov_matrix_inv@secondfactor\n",
    "    exponent = math.exp(-temp)\n",
    "    \n",
    "    return (factor) * exponent\n",
    "\n",
    "\n",
    "def calculate_all_probabilities(class_wise_stats,cov_matrix, input_vector):\n",
    "    \n",
    "    mean_dict = {}\n",
    "\n",
    "    for class_value, class_data in class_wise_stats.items():\n",
    "        for i in range(len(class_data)):\n",
    "            if class_value not in mean_dict:\n",
    "                mean_dict[class_value] = []\n",
    "            mean_dict[class_value].append(class_data[i][0]) # i th row is the ith feature\n",
    "    \n",
    "    \n",
    "    # mean_dict\n",
    "    probabilities = {}\n",
    "    for class_value,class_data in mean_dict.items():\n",
    "        mean_vector= mean_dict[class_value]        \n",
    "        x = input_vector\n",
    "        probabilities[class_value] = calculate_probability (x, mean_vector, cov_matrix)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "\n",
    "def predict(class_wise_stats,cov_matrix, input_vector):\n",
    "    probabilities = calculate_all_probabilities(class_wise_stats,cov_matrix, input_vector)\n",
    "    label = None\n",
    "    prob = -1\n",
    "    \n",
    "    for class_value, probability in probabilities.items():\n",
    "        if label is None or probability > prob:\n",
    "            prob = probability\n",
    "            label = class_value\n",
    "    return label\n",
    "\n",
    "\n",
    "def get_predictions(class_wise_stats,cov_matrix, test_dataset):\n",
    "    predictions = []\n",
    "    for i in range(len(test_dataset)):\n",
    "        result = predict(class_wise_stats,cov_matrix,test_dataset[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    "\n",
    "def getAccuracy(test_dataset, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(test_dataset)):\n",
    "        if test_dataset[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(test_dataset))) * 100.0\n",
    "\n",
    "orig_dataset = pd.read_csv(\"RainInAustralia.csv\")\n",
    "\n",
    "new_dataset = np.array(orig_dataset)\n",
    "\n",
    "split_ratio = 0.75\n",
    "\n",
    "training_set, test_dataset = split_dataset(new_dataset, split_ratio)\n",
    "\n",
    "training_set = np.array(training_set)\n",
    "test_dataset = np.array(test_dataset)\n",
    "\n",
    "\n",
    "parameters,cov_matrix = generate_stats_by_class(training_set)\n",
    "\n",
    "\n",
    "\n",
    "predictions = get_predictions(parameters,cov_matrix, test_dataset[:,:-1])\n",
    "\n",
    "getAccuracy(test_dataset, predictions)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
